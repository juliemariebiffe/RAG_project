{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1bf7dcfa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "26947c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "from langchain_openai import AzureChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5be94d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eb9845a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHUNK_SIZE = 1_000\n",
    "CHUNK_OVERLAP = 200\n",
    "\n",
    "\n",
    "def read_config(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        try:\n",
    "            config = yaml.safe_load(file)\n",
    "            return config\n",
    "        except yaml.YAMLError as e:\n",
    "            print(f\"Error reading YAML file: {e}\")\n",
    "            return None\n",
    "\n",
    "config = read_config(\"secrets/config.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "deda1baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder = AzureOpenAIEmbeddings(\n",
    "    azure_endpoint=config[\"embedding\"][\"azure_endpoint\"],\n",
    "    azure_deployment=config[\"embedding\"][\"azure_deployment\"],\n",
    "    openai_api_version=config[\"embedding\"][\"azure_api_version\"],\n",
    "    api_key=config[\"embedding\"][\"azure_api_key\"]\n",
    ")\n",
    "\n",
    "vector_store = InMemoryVectorStore(embedder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "93d571f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = AzureChatOpenAI(\n",
    "    azure_endpoint=config[\"chat\"][\"azure_endpoint\"],\n",
    "    azure_deployment=config[\"chat\"][\"azure_deployment\"],\n",
    "    openai_api_version=config[\"chat\"][\"azure_api_version\"],\n",
    "    api_key=config[\"chat\"][\"azure_api_key\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "477892b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_meta_doc(extract: str) -> str:\n",
    "    \"\"\"Generate a synthetic metadata description of the content.\n",
    "    \"\"\"\n",
    "    messages = [\n",
    "    (\n",
    "        \"system\",\n",
    "        \"You are a librarian extracting metadata from documents.\",\n",
    "    ),\n",
    "    (\n",
    "        \"user\",\n",
    "        \"\"\"Extract from the content the following metadata.\n",
    "        Answer 'unknown' if you cannot find or generate the information.\n",
    "        Metadata list:\n",
    "        - title\n",
    "        - author\n",
    "        - source\n",
    "        - type of content (e.g. scientific paper, litterature, news, etc.)\n",
    "        - language\n",
    "        - themes as a list of keywords\n",
    "\n",
    "        <content>\n",
    "        {}\n",
    "        </content>\n",
    "        \"\"\".format(extract),\n",
    "    ),]\n",
    "    response = llm.invoke(messages)\n",
    "    return response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c0480a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_pdf_file(file_path: str, doc_name: str, use_meta_doc: bool=True):\n",
    "    \"\"\"Store a pdf file in the vector store.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): file path to the PDF file\n",
    "    \"\"\"\n",
    "    loader = PyMuPDFLoader(file_path)\n",
    "    docs = loader.load()\n",
    "    # TODO: make a constant of chunk_size and chunk_overlap\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=CHUNK_SIZE,\n",
    "                                                   chunk_overlap=CHUNK_OVERLAP)\n",
    "    all_splits = text_splitter.split_documents(docs)\n",
    "    for split in all_splits:\n",
    "        split.metadata = {\n",
    "            'document_name': doc_name,\n",
    "            'insert_date': datetime.now()\n",
    "            }\n",
    "    if use_meta_doc:\n",
    "        extract = '\\n\\n'.join([split.page_content for split in all_splits[:min(10, len(all_splits))]])\n",
    "        meta_doc = Document(page_content=get_meta_doc(extract),\n",
    "                            metadata={\n",
    "                                'document_name': doc_name,\n",
    "                                'insert_date': datetime.now()\n",
    "                                })\n",
    "        all_splits.append(meta_doc)\n",
    "    _ = vector_store.add_documents(documents=all_splits)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4dc9355e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_file_from_store(name: str) -> int:\n",
    "    ids_to_remove = []\n",
    "    for (id, doc) in vector_store.store.items():\n",
    "        if name == doc['metadata']['document_name']:\n",
    "            ids_to_remove.append(id)\n",
    "    vector_store.delete(ids_to_remove)\n",
    "    #print('File deleted:', name)\n",
    "    return len(ids_to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "11e59a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inspect_vector_store(top_n: int=10) -> list:\n",
    "    docs = []\n",
    "    for index, (id, doc) in enumerate(vector_store.store.items()):\n",
    "        if index < top_n:\n",
    "            docs.append({\n",
    "                'id': id,\n",
    "                'document_name': doc['metadata']['document_name'],\n",
    "                'insert_date': doc['metadata']['insert_date'],\n",
    "                'text': doc['text']\n",
    "                })\n",
    "            # docs have keys 'id', 'vector', 'text', 'metadata'\n",
    "            # print(f\"{id} {doc['metadata']['document_name']}: {doc['text']}\")\n",
    "        else:\n",
    "            break\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7697f5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vector_store_info():\n",
    "    nb_docs = 0\n",
    "    max_date, min_date = None, None\n",
    "    documents = set()\n",
    "    for (id, doc) in vector_store.store.items():\n",
    "        nb_docs += 1\n",
    "        if max_date is None or max_date < doc['metadata']['insert_date']:\n",
    "            max_date = doc['metadata']['insert_date']\n",
    "        if min_date is None or min_date > doc['metadata']['insert_date']:\n",
    "            min_date = doc['metadata']['insert_date']\n",
    "        documents.add(doc['metadata']['document_name'])\n",
    "    return {\n",
    "        'nb_chunks': nb_docs,\n",
    "        'min_insert_date': min_date,\n",
    "        'max_insert_date': max_date,\n",
    "        'nb_documents': len(documents)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "03d65aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(question: str):\n",
    "    \"\"\"Retrieve documents similar to a question.\n",
    "\n",
    "    Args:\n",
    "        question (str): text of the question\n",
    "\n",
    "    Returns:\n",
    "        list[TODO]: list of similar documents retrieved from the vector store\n",
    "    \"\"\"\n",
    "    retrieved_docs = vector_store.similarity_search(question)\n",
    "    return retrieved_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b618dd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_qa_messages(question: str, context: str) -> list[str]:\n",
    "    messages = [\n",
    "    (\n",
    "        \"system\",\n",
    "        \"You are an assistant for question-answering tasks.\",\n",
    "    ),\n",
    "    (\n",
    "        \"system\",\n",
    "        \"\"\"Use the following pieces of retrieved context to answer the question.\n",
    "        If you don't know the answer, just say that you don't know.\n",
    "        Use three sentences maximum and keep the answer concise.\n",
    "        {}\"\"\".format(context),\n",
    "    ),\n",
    "    (  \n",
    "        \"user\",\n",
    "        question\n",
    "    ),]\n",
    "    return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "142391b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_question(question: str) -> str:\n",
    "    \"\"\"Answer a question by retrieving similar documents in the store.\n",
    "\n",
    "    Args:\n",
    "        question (str): text of the question\n",
    "\n",
    "    Returns:\n",
    "        str: text of the answer\n",
    "    \"\"\"\n",
    "    inspect_vector_store()\n",
    "    docs = retrieve(question)\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "    print(\"Question:\", question)\n",
    "    print(\"------\")\n",
    "    for doc in docs:\n",
    "        print(\"Chunk:\", doc.id)\n",
    "        print(doc.page_content)\n",
    "        print(\"------\")\n",
    "    messages = build_qa_messages(question, docs_content)\n",
    "    response = llm.invoke(messages)\n",
    "    return response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41d7984",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d41e608",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8496dd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1da2710",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63fdfafc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04b16fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5dce0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb356e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc80d7da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d953d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c532b2b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cacc269",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4aae8ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
