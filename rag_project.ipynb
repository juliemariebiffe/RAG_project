{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "bf595967",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "4caa6e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "from langchain_openai import AzureChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "f3d6a8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHUNK_SIZE = 1_000\n",
    "CHUNK_OVERLAP = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "24e8b6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import yaml\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "5b31f455",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '__file__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[104], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mErreur de lecture du fichier YAML : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     14\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m config \u001b[38;5;241m=\u001b[39m \u001b[43mread_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[104], line 5\u001b[0m, in \u001b[0;36mread_config\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01myaml\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m base_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mabspath(\u001b[38;5;18;43m__file__\u001b[39;49m))\n\u001b[0;32m      6\u001b[0m config_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(base_dir, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msecrets\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconfig.yaml\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;31mNameError\u001b[0m: name '__file__' is not defined"
     ]
    }
   ],
   "source": [
    "def read_config():\n",
    "    import os\n",
    "    import yaml\n",
    "\n",
    "    base_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "    config_path = os.path.join(base_dir, 'secrets', 'config.yaml')\n",
    "\n",
    "    try:\n",
    "        with open(config_path, 'r') as file:\n",
    "            config = yaml.safe_load(file)\n",
    "            return config\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur de lecture du fichier YAML : {e}\")\n",
    "        raise\n",
    "\n",
    "config = read_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329f817a",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder = AzureOpenAIEmbeddings(\n",
    "    azure_endpoint=config[\"embedding\"][\"azure_endpoint\"],\n",
    "    azure_deployment=config[\"embedding\"][\"azure_deployment\"],\n",
    "    openai_api_version=config[\"embedding\"][\"azure_api_version\"],\n",
    "    api_key=config[\"embedding\"][\"azure_api_key\"]\n",
    ")\n",
    "\n",
    "vector_store = InMemoryVectorStore(embedder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a56d863",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = AzureChatOpenAI(\n",
    "    azure_endpoint=config[\"chat\"][\"azure_endpoint\"],\n",
    "    azure_deployment=config[\"chat\"][\"azure_deployment\"],\n",
    "    openai_api_version=config[\"chat\"][\"azure_api_version\"],\n",
    "    api_key=config[\"chat\"][\"azure_api_key\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc70bf69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_meta_doc(extract: str) -> str:\n",
    "    \"\"\"Generate a synthetic metadata description of the content.\n",
    "    \"\"\"\n",
    "    messages = [\n",
    "    (\n",
    "        \"system\",\n",
    "        \"You are a librarian extracting metadata from documents.\",\n",
    "    ),\n",
    "    (\n",
    "        \"user\",\n",
    "        \"\"\"Extract from the content the following metadata.\n",
    "        Answer 'unknown' if you cannot find or generate the information.\n",
    "        Metadata list:\n",
    "        - title\n",
    "        - author\n",
    "        - source\n",
    "        - type of content (e.g. scientific paper, litterature, news, etc.)\n",
    "        - language\n",
    "        - themes as a list of keywords\n",
    "\n",
    "        <content>\n",
    "        {}\n",
    "        </content>\n",
    "        \"\"\".format(extract),\n",
    "    ),]\n",
    "    response = llm.invoke(messages)\n",
    "    return response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "fbaf80ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_pdf_file(file_path: str, doc_name: str, use_meta_doc: bool=True):\n",
    "    \"\"\"Store a pdf file in the vector store.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): file path to the PDF file\n",
    "    \"\"\"\n",
    "    loader = PyMuPDFLoader(file_path)\n",
    "    docs = loader.load()\n",
    "    # TODO: make a constant of chunk_size and chunk_overlap\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=CHUNK_SIZE,\n",
    "                                                   chunk_overlap=CHUNK_OVERLAP)\n",
    "    all_splits = text_splitter.split_documents(docs)\n",
    "    for split in all_splits:\n",
    "        split.metadata = {\n",
    "            'document_name': doc_name,\n",
    "            'insert_date': datetime.now()\n",
    "            }\n",
    "    if use_meta_doc:\n",
    "        extract = '\\n\\n'.join([split.page_content for split in all_splits[:min(10, len(all_splits))]])\n",
    "        meta_doc = Document(page_content=get_meta_doc(extract),\n",
    "                            metadata={\n",
    "                                'document_name': doc_name,\n",
    "                                'insert_date': datetime.now()\n",
    "                                })\n",
    "        all_splits.append(meta_doc)\n",
    "    _ = vector_store.add_documents(documents=all_splits)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "0861b224",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_file_from_store(name: str) -> int:\n",
    "    ids_to_remove = []\n",
    "    for (id, doc) in vector_store.store.items():\n",
    "        if name == doc['metadata']['document_name']:\n",
    "            ids_to_remove.append(id)\n",
    "    vector_store.delete(ids_to_remove)\n",
    "    #print('File deleted:', name)\n",
    "    return len(ids_to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "f02e4bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inspect_vector_store(top_n: int=10) -> list:\n",
    "    docs = []\n",
    "    for index, (id, doc) in enumerate(vector_store.store.items()):\n",
    "        if index < top_n:\n",
    "            docs.append({\n",
    "                'id': id,\n",
    "                'document_name': doc['metadata']['document_name'],\n",
    "                'insert_date': doc['metadata']['insert_date'],\n",
    "                'text': doc['text']\n",
    "                })\n",
    "            # docs have keys 'id', 'vector', 'text', 'metadata'\n",
    "            # print(f\"{id} {doc['metadata']['document_name']}: {doc['text']}\")\n",
    "        else:\n",
    "            break\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "3187a298",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vector_store_info():\n",
    "    nb_docs = 0\n",
    "    max_date, min_date = None, None\n",
    "    documents = set()\n",
    "    for (id, doc) in vector_store.store.items():\n",
    "        nb_docs += 1\n",
    "        if max_date is None or max_date < doc['metadata']['insert_date']:\n",
    "            max_date = doc['metadata']['insert_date']\n",
    "        if min_date is None or min_date > doc['metadata']['insert_date']:\n",
    "            min_date = doc['metadata']['insert_date']\n",
    "        documents.add(doc['metadata']['document_name'])\n",
    "    return {\n",
    "        'nb_chunks': nb_docs,\n",
    "        'min_insert_date': min_date,\n",
    "        'max_insert_date': max_date,\n",
    "        'nb_documents': len(documents)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "c4124d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(question: str):\n",
    "    \"\"\"Retrieve documents similar to a question.\n",
    "\n",
    "    Args:\n",
    "        question (str): text of the question\n",
    "\n",
    "    Returns:\n",
    "        list[TODO]: list of similar documents retrieved from the vector store\n",
    "    \"\"\"\n",
    "    retrieved_docs = vector_store.similarity_search(question)\n",
    "    return retrieved_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "9112ae80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_qa_messages(question: str, context: str) -> list[str]:\n",
    "    messages = [\n",
    "    (\n",
    "        \"system\",\n",
    "        \"You are an assistant for question-answering tasks.\",\n",
    "    ),\n",
    "    (\n",
    "        \"system\",\n",
    "        \"\"\"Use the following pieces of retrieved context to answer the question.\n",
    "        If you don't know the answer, just say that you don't know.\n",
    "        Use three sentences maximum and keep the answer concise.\n",
    "        {}\"\"\".format(context),\n",
    "    ),\n",
    "    (  \n",
    "        \"user\",\n",
    "        question\n",
    "    ),]\n",
    "    return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "cd3ea27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_question(question: str) -> str:\n",
    "    \"\"\"Answer a question by retrieving similar documents in the store.\n",
    "\n",
    "    Args:\n",
    "        question (str): text of the question\n",
    "\n",
    "    Returns:\n",
    "        str: text of the answer\n",
    "    \"\"\"\n",
    "    inspect_vector_store()\n",
    "    docs = retrieve(question)\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "    print(\"Question:\", question)\n",
    "    print(\"------\")\n",
    "    for doc in docs:\n",
    "        print(\"Chunk:\", doc.id)\n",
    "        print(doc.page_content)\n",
    "        print(\"------\")\n",
    "    messages = build_qa_messages(question, docs_content)\n",
    "    response = llm.invoke(messages)\n",
    "    return response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac2111b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6e124a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbe7be8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1925446",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5090bf65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34441231",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30652e29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e255f94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769f25c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597e17d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9195dc10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e06d4f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254ae7ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
