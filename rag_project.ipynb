{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce2ce07e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7c2b216a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "from langchain_openai import AzureChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "47000694",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHUNK_SIZE = 1_000\n",
    "CHUNK_OVERLAP = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "966418ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import yaml\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cd4cf8b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier téléchargé avec succès : C:/Users/Julie-Marie Biffe/OneDrive/Documents/rag/secrets/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# Chemin local\n",
    "local_path = \"C:/Users/Julie-Marie Biffe/OneDrive/Documents/rag/secrets/config.yaml\"\n",
    "\n",
    "# URL brute GitHub\n",
    "url = \"https://raw.githubusercontent.com/juliemariebiffe/RAG_project/main/secrets/config.yaml\"\n",
    "\n",
    "\n",
    "os.makedirs(os.path.dirname(local_path), exist_ok=True)\n",
    "response = requests.get(url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    with open(local_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(response.text)\n",
    "    print(f\"Fichier téléchargé avec succès : {local_path}\")\n",
    "else:\n",
    "    print(f\"Erreur lors du téléchargement (code {response.status_code})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42706ae4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0f81c8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_config():\n",
    "    import os\n",
    "    import yaml\n",
    "\n",
    "    # Utilise le répertoire de travail courant\n",
    "    base_dir = os.getcwd()\n",
    "    config_path = os.path.join(base_dir, 'secrets', 'config.yaml')\n",
    "\n",
    "    try:\n",
    "        with open(config_path, 'r') as file:\n",
    "            config = yaml.safe_load(file)\n",
    "            return config\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur de lecture du fichier YAML : {e}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "config = read_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "20d94c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "\n",
    "openai_api_key = st.secrets[\"OPENAI_API_KEY\"]\n",
    "\n",
    "embedding_azure_endpoint = st.secrets[\"EMBEDDING_AZURE_ENDPOINT\"]\n",
    "embedding_azure_deployment = st.secrets[\"EMBEDDING_AZURE_DEPLOYMENT\"]\n",
    "embedding_azure_api_version = st.secrets[\"EMBEDDING_AZURE_API_VERSION\"]\n",
    "embedding_azure_api_key = st.secrets[\"EMBEDDING_AZURE_API_KEY\"]\n",
    "\n",
    "chat_azure_endpoint = st.secrets[\"CHAT_AZURE_ENDPOINT\"]\n",
    "chat_azure_deployment = st.secrets[\"CHAT_AZURE_DEPLOYMENT\"]\n",
    "chat_azure_api_version = st.secrets[\"CHAT_AZURE_API_VERSION\"]\n",
    "chat_azure_api_key = st.secrets[\"CHAT_AZURE_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b1bb0647",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder = AzureOpenAIEmbeddings(\n",
    "    azure_endpoint=config[\"embedding\"][\"azure_endpoint\"],\n",
    "    azure_deployment=config[\"embedding\"][\"azure_deployment\"],\n",
    "    openai_api_version=config[\"embedding\"][\"azure_api_version\"],\n",
    "    api_key=config[\"embedding\"][\"azure_api_key\"]\n",
    ")\n",
    "\n",
    "vector_store = InMemoryVectorStore(embedder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "72b69b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = AzureChatOpenAI(\n",
    "    azure_endpoint=config[\"chat\"][\"azure_endpoint\"],\n",
    "    azure_deployment=config[\"chat\"][\"azure_deployment\"],\n",
    "    openai_api_version=config[\"chat\"][\"azure_api_version\"],\n",
    "    api_key=config[\"chat\"][\"azure_api_key\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9a69f129",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_meta_doc(extract: str) -> str:\n",
    "    \"\"\"Generate a synthetic metadata description of the content.\n",
    "    \"\"\"\n",
    "    messages = [\n",
    "    (\n",
    "        \"system\",\n",
    "        \"You are a librarian extracting metadata from documents.\",\n",
    "    ),\n",
    "    (\n",
    "        \"user\",\n",
    "        \"\"\"Extract from the content the following metadata.\n",
    "        Answer 'unknown' if you cannot find or generate the information.\n",
    "        Metadata list:\n",
    "        - title\n",
    "        - author\n",
    "        - source\n",
    "        - type of content (e.g. scientific paper, litterature, news, etc.)\n",
    "        - language\n",
    "        - themes as a list of keywords\n",
    "\n",
    "        <content>\n",
    "        {}\n",
    "        </content>\n",
    "        \"\"\".format(extract),\n",
    "    ),]\n",
    "    response = llm.invoke(messages)\n",
    "    return response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "137d2b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_pdf_file(file_path: str, doc_name: str, use_meta_doc: bool=True):\n",
    "    \"\"\"Store a pdf file in the vector store.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): file path to the PDF file\n",
    "    \"\"\"\n",
    "    loader = PyMuPDFLoader(file_path)\n",
    "    docs = loader.load()\n",
    "    # TODO: make a constant of chunk_size and chunk_overlap\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=CHUNK_SIZE,\n",
    "                                                   chunk_overlap=CHUNK_OVERLAP)\n",
    "    all_splits = text_splitter.split_documents(docs)\n",
    "    for split in all_splits:\n",
    "        split.metadata = {\n",
    "            'document_name': doc_name,\n",
    "            'insert_date': datetime.now()\n",
    "            }\n",
    "    if use_meta_doc:\n",
    "        extract = '\\n\\n'.join([split.page_content for split in all_splits[:min(10, len(all_splits))]])\n",
    "        meta_doc = Document(page_content=get_meta_doc(extract),\n",
    "                            metadata={\n",
    "                                'document_name': doc_name,\n",
    "                                'insert_date': datetime.now()\n",
    "                                })\n",
    "        all_splits.append(meta_doc)\n",
    "    _ = vector_store.add_documents(documents=all_splits)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "58b56e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_file_from_store(name: str) -> int:\n",
    "    ids_to_remove = []\n",
    "    for (id, doc) in vector_store.store.items():\n",
    "        if name == doc['metadata']['document_name']:\n",
    "            ids_to_remove.append(id)\n",
    "    vector_store.delete(ids_to_remove)\n",
    "    #print('File deleted:', name)\n",
    "    return len(ids_to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e05645eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inspect_vector_store(top_n: int=10) -> list:\n",
    "    docs = []\n",
    "    for index, (id, doc) in enumerate(vector_store.store.items()):\n",
    "        if index < top_n:\n",
    "            docs.append({\n",
    "                'id': id,\n",
    "                'document_name': doc['metadata']['document_name'],\n",
    "                'insert_date': doc['metadata']['insert_date'],\n",
    "                'text': doc['text']\n",
    "                })\n",
    "            # docs have keys 'id', 'vector', 'text', 'metadata'\n",
    "            # print(f\"{id} {doc['metadata']['document_name']}: {doc['text']}\")\n",
    "        else:\n",
    "            break\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5a5d7a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vector_store_info():\n",
    "    nb_docs = 0\n",
    "    max_date, min_date = None, None\n",
    "    documents = set()\n",
    "    for (id, doc) in vector_store.store.items():\n",
    "        nb_docs += 1\n",
    "        if max_date is None or max_date < doc['metadata']['insert_date']:\n",
    "            max_date = doc['metadata']['insert_date']\n",
    "        if min_date is None or min_date > doc['metadata']['insert_date']:\n",
    "            min_date = doc['metadata']['insert_date']\n",
    "        documents.add(doc['metadata']['document_name'])\n",
    "    return {\n",
    "        'nb_chunks': nb_docs,\n",
    "        'min_insert_date': min_date,\n",
    "        'max_insert_date': max_date,\n",
    "        'nb_documents': len(documents)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "69b28275",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(question: str):\n",
    "    \"\"\"Retrieve documents similar to a question.\n",
    "\n",
    "    Args:\n",
    "        question (str): text of the question\n",
    "\n",
    "    Returns:\n",
    "        list[TODO]: list of similar documents retrieved from the vector store\n",
    "    \"\"\"\n",
    "    retrieved_docs = vector_store.similarity_search(question)\n",
    "    return retrieved_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3b3a645d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_qa_messages(question: str, context: str) -> list[str]:\n",
    "    messages = [\n",
    "    (\n",
    "        \"system\",\n",
    "        \"You are an assistant for question-answering tasks.\",\n",
    "    ),\n",
    "    (\n",
    "        \"system\",\n",
    "        \"\"\"Use the following pieces of retrieved context to answer the question.\n",
    "        If you don't know the answer, just say that you don't know.\n",
    "        Use three sentences maximum and keep the answer concise.\n",
    "        {}\"\"\".format(context),\n",
    "    ),\n",
    "    (  \n",
    "        \"user\",\n",
    "        question\n",
    "    ),]\n",
    "    return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b63aed2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_question(question: str) -> str:\n",
    "    \"\"\"Answer a question by retrieving similar documents in the store.\n",
    "\n",
    "    Args:\n",
    "        question (str): text of the question\n",
    "\n",
    "    Returns:\n",
    "        str: text of the answer\n",
    "    \"\"\"\n",
    "    inspect_vector_store()\n",
    "    docs = retrieve(question)\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "    print(\"Question:\", question)\n",
    "    print(\"------\")\n",
    "    for doc in docs:\n",
    "        print(\"Chunk:\", doc.id)\n",
    "        print(doc.page_content)\n",
    "        print(\"------\")\n",
    "    messages = build_qa_messages(question, docs_content)\n",
    "    response = llm.invoke(messages)\n",
    "    return response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50011dae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a6325f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8279fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd255e69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d597abfa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5804835",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb45cf7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42605a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0644c106",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8343e06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe71f3f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ef359c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32065c8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
